{
  "id": "domain3-slurm-full-setup",
  "title": "Complete Slurm Cluster Configuration",
  "domain": "domain3",
  "difficulty": "advanced",
  "description": "Learn how to configure a complete Slurm cluster from scratch including partitions, GRES for GPUs, QOS policies, and accounting. This lab covers the full Slurm setup for GPU workloads.",
  "learningObjectives": [
    "Understand Slurm architecture for GPU clusters",
    "Configure slurm.conf for GPU nodes",
    "Set up GRES for GPU resources",
    "Configure partitions and QOS",
    "Enable Slurm accounting"
  ],
  "faults": [],
  "initialClusterState": {},
  "steps": [
    {
      "id": "step1",
      "title": "Understand Slurm Components",
      "description": "Learn about Slurm daemons and their roles in the cluster.",
      "objectives": [
        "Understand slurmctld role",
        "Understand slurmd role",
        "Know configuration file locations"
      ],
      "expectedCommands": ["scontrol show config | head -30", "sinfo"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must understand Slurm components",
          "expectedCommands": ["scontrol show config", "sinfo"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "slurmctld: Central controller daemon",
        "slurmd: Compute node daemon",
        "slurmdbd: Database daemon for accounting",
        "Config files in /etc/slurm/",
        "slurm.conf is main configuration file"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "Slurm Architecture",
          "url": "https://slurm.schedmd.com/overview.html"
        }
      ]
    },
    {
      "id": "step2",
      "title": "Review slurm.conf Configuration",
      "description": "Examine the main Slurm configuration file structure.",
      "objectives": [
        "Understand key configuration parameters",
        "Review cluster-level settings",
        "Check node definitions"
      ],
      "expectedCommands": [
        "cat /etc/slurm/slurm.conf | head -50",
        "scontrol show config | grep -i gres"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must review slurm.conf",
          "expectedCommands": [
            "cat /etc/slurm/slurm.conf",
            "scontrol show config"
          ],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "ClusterName identifies the cluster",
        "SlurmctldHost specifies controller",
        "NodeName defines compute nodes",
        "PartitionName defines job queues",
        "GresTypes enables GPU support"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "slurm.conf",
          "url": "https://slurm.schedmd.com/slurm.conf.html"
        }
      ]
    },
    {
      "id": "step3",
      "title": "Configure GRES for GPUs",
      "description": "Set up Generic Resource (GRES) configuration for GPU scheduling.",
      "objectives": [
        "Understand GRES configuration",
        "Review gres.conf file",
        "Verify GPU GRES settings"
      ],
      "expectedCommands": [
        "cat /etc/slurm/gres.conf",
        "scontrol show node | grep -i gres"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must configure GRES",
          "expectedCommands": [
            "cat /etc/slurm/gres.conf",
            "scontrol show node"
          ],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "GRES enables GPU scheduling",
        "Format: Name=gpu File=/dev/nvidia[0-7]",
        "Can specify GPU types: gpu:a100:8",
        "AutoDetect=nvml auto-discovers GPUs",
        "Nodes must have matching GRES in slurm.conf"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "GRES Configuration",
          "url": "https://slurm.schedmd.com/gres.html"
        }
      ]
    },
    {
      "id": "step4",
      "title": "Define Compute Nodes",
      "description": "Configure DGX nodes in slurm.conf with proper resources.",
      "objectives": [
        "Define node names and resources",
        "Configure GPU resources per node",
        "Set node features and weights"
      ],
      "expectedCommands": ["scontrol show node", "sinfo -N -l"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must define compute nodes",
          "expectedCommands": ["scontrol show node", "sinfo -N -l"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "NodeName=dgx[01-08] defines 8 nodes",
        "CPUs, RealMemory, Sockets, CoresPerSocket",
        "Gres=gpu:a100:8 for 8 A100 GPUs",
        "Features allow job targeting",
        "Weight affects scheduling priority"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "Node Configuration",
          "url": "https://slurm.schedmd.com/slurm.conf.html"
        }
      ]
    },
    {
      "id": "step5",
      "title": "Configure Partitions",
      "description": "Set up job partitions (queues) for different workload types.",
      "objectives": [
        "Create GPU partition",
        "Set partition limits",
        "Configure partition priorities"
      ],
      "expectedCommands": ["sinfo -s", "scontrol show partition"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must configure partitions",
          "expectedCommands": ["sinfo -s", "scontrol show partition"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "PartitionName=gpu Nodes=dgx[01-08]",
        "Default=YES for default partition",
        "MaxTime sets wall clock limit",
        "MaxNodes limits job size",
        "PriorityTier affects scheduling"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "Partitions",
          "url": "https://slurm.schedmd.com/slurm.conf.html"
        }
      ]
    },
    {
      "id": "step6",
      "title": "Set Up Quality of Service (QOS)",
      "description": "Configure QOS policies for job prioritization and limits.",
      "objectives": [
        "Understand QOS concept",
        "Create QOS policies",
        "Assign QOS to users/accounts"
      ],
      "expectedCommands": ["sacctmgr show qos", "sacctmgr show assoc"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must set up QOS",
          "expectedCommands": ["sacctmgr show qos", "sacctmgr show assoc"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "QOS controls job limits and priority",
        "MaxTRES limits total resources",
        "Priority affects scheduling order",
        "Can limit GPUs per user/account",
        "Preemption based on QOS priority"
      ],
      "estimatedDuration": 8,
      "documentationLinks": [
        {
          "title": "QOS Configuration",
          "url": "https://slurm.schedmd.com/qos.html"
        }
      ]
    },
    {
      "id": "step7",
      "title": "Test Job Submission",
      "description": "Verify Slurm configuration by submitting test jobs.",
      "objectives": [
        "Submit GPU job",
        "Verify GPU allocation",
        "Check job status"
      ],
      "expectedCommands": [
        "sbatch --gres=gpu:1 --wrap=\"nvidia-smi\"",
        "squeue",
        "scontrol show job"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must test job submission",
          "expectedCommands": ["sbatch --gres=gpu:1", "squeue"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "--gres=gpu:1 requests 1 GPU",
        "--gres=gpu:a100:2 requests specific type",
        "Check CUDA_VISIBLE_DEVICES in job",
        "squeue shows job queue",
        "sacct shows completed job info"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "Job Submission",
          "url": "https://slurm.schedmd.com/sbatch.html"
        }
      ]
    },
    {
      "id": "step8",
      "title": "Verify Accounting",
      "description": "Check Slurm accounting is capturing job information.",
      "objectives": [
        "Verify slurmdbd running",
        "Check job accounting records",
        "View resource usage"
      ],
      "expectedCommands": [
        "sacct -j <jobid>",
        "sacct --format=JobID,JobName,Partition,AllocGRES,State,Elapsed"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must verify accounting",
          "expectedCommands": ["sacct"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "sacct shows job accounting info",
        "AllocGRES shows GPU allocation",
        "Elapsed shows runtime",
        "ReqMem/MaxRSS show memory usage",
        "Export with --parsable2 for scripts"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "Slurm Accounting",
          "url": "https://slurm.schedmd.com/accounting.html"
        }
      ]
    }
  ],
  "successCriteria": [
    "Understood Slurm components",
    "Reviewed slurm.conf configuration",
    "Configured GRES for GPUs",
    "Defined compute nodes",
    "Configured partitions",
    "Set up QOS policies",
    "Tested job submission",
    "Verified accounting"
  ],
  "estimatedTime": 55,
  "prerequisites": ["domain3-slurm-config"],
  "tags": [
    "slurm",
    "cluster",
    "scheduler",
    "gres",
    "configuration",
    "advanced"
  ],
  "tier": 3,
  "commandFamilies": ["cluster-tools"],
  "explanationGateId": "gate-domain3-slurm-full-setup",
  "toolHints": false
}
