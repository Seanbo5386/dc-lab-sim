{
  "id": "domain3-k8s-gpu-operator",
  "title": "Kubernetes GPU Operator Deployment and Validation",
  "domain": "domain3",
  "difficulty": "intermediate",
  "description": "Deploy and validate the NVIDIA GPU Operator on Kubernetes for GPU-enabled workloads. The GPU Operator automates the management of all NVIDIA software components needed to provision GPUs in Kubernetes, including drivers, container runtime, and device plugins.",
  "learningObjectives": [
    "Understand GPU Operator architecture and components",
    "Deploy GPU Operator using Helm",
    "Validate GPU visibility in Kubernetes",
    "Run GPU-enabled test workloads",
    "Troubleshoot common GPU Operator issues"
  ],
  "faults": [],
  "initialClusterState": {},
  "steps": [
    {
      "id": "step1",
      "title": "Verify Kubernetes Cluster Prerequisites",
      "description": "Before deploying the GPU Operator, verify the Kubernetes cluster meets prerequisites including node labels and supported container runtime.",
      "objectives": [
        "Check Kubernetes cluster status",
        "Verify node readiness",
        "Check container runtime (containerd)",
        "Identify GPU nodes"
      ],
      "expectedCommands": [
        "kubectl get nodes -o wide",
        "kubectl describe node dgx-01 | grep -i gpu",
        "kubectl get nodes --show-labels | grep nvidia"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must verify cluster prerequisites",
          "expectedCommands": ["kubectl get nodes", "kubectl describe node"]
        }
      ],
      "hints": [
        "All nodes should be in 'Ready' state",
        "GPU nodes need 'nvidia.com/gpu' label",
        "containerd is the recommended container runtime",
        "Verify Kubernetes version compatibility (1.21+)",
        "Check if NFD (Node Feature Discovery) is deployed"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "GPU Operator Prerequisites",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html"
        }
      ]
    },
    {
      "id": "step2",
      "title": "Add NVIDIA Helm Repository",
      "description": "Configure Helm to access the NVIDIA repository containing the GPU Operator chart.",
      "objectives": [
        "Add NVIDIA Helm repository",
        "Update repository cache",
        "Search for GPU Operator chart"
      ],
      "expectedCommands": [
        "helm repo add nvidia https://helm.ngc.nvidia.com/nvidia",
        "helm repo update",
        "helm search repo nvidia/gpu-operator"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must configure Helm repository",
          "expectedCommands": ["helm repo add", "helm search repo"]
        }
      ],
      "hints": [
        "NVIDIA Helm repo: https://helm.ngc.nvidia.com/nvidia",
        "Use 'helm repo update' after adding new repos",
        "Search shows available chart versions",
        "Latest stable version recommended for production",
        "Consider NGC API key for private charts"
      ],
      "estimatedDuration": 3,
      "documentationLinks": [
        {
          "title": "GPU Operator Helm Chart",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html"
        }
      ]
    },
    {
      "id": "step3",
      "title": "Deploy GPU Operator",
      "description": "Install the GPU Operator using Helm with appropriate configuration for the DGX environment.",
      "objectives": [
        "Create gpu-operator namespace",
        "Deploy GPU Operator with Helm",
        "Configure operator for pre-installed drivers",
        "Monitor deployment progress"
      ],
      "expectedCommands": [
        "kubectl create namespace gpu-operator",
        "helm install gpu-operator nvidia/gpu-operator -n gpu-operator --set driver.enabled=false",
        "kubectl get pods -n gpu-operator -w"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must deploy GPU Operator",
          "expectedCommands": ["helm install", "kubectl get pods"]
        }
      ],
      "hints": [
        "DGX systems have pre-installed drivers: --set driver.enabled=false",
        "Use '--wait' flag for Helm to wait for readiness",
        "Operator creates daemonsets for each component",
        "Watch pods with -w to see startup progress",
        "All pods should reach 'Running' state"
      ],
      "estimatedDuration": 8,
      "documentationLinks": [
        {
          "title": "GPU Operator Installation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html"
        }
      ]
    },
    {
      "id": "step4",
      "title": "Verify GPU Operator Components",
      "description": "Verify all GPU Operator components are running correctly including device plugin, container toolkit, and feature discovery.",
      "objectives": [
        "Check all operator pods are running",
        "Verify device plugin daemonset",
        "Check container toolkit deployment",
        "Verify GPU feature discovery"
      ],
      "expectedCommands": [
        "kubectl get pods -n gpu-operator",
        "kubectl get daemonset -n gpu-operator",
        "kubectl logs -n gpu-operator -l app=nvidia-device-plugin-daemonset"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must verify operator components",
          "expectedCommands": [
            "kubectl get pods -n gpu-operator",
            "kubectl get daemonset"
          ]
        }
      ],
      "hints": [
        "Key components: device-plugin, container-toolkit, dcgm-exporter",
        "Each component runs as DaemonSet on GPU nodes",
        "Check logs for initialization errors",
        "DCGM exporter provides Prometheus metrics",
        "GPU Feature Discovery (GFD) labels nodes with GPU info"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "GPU Operator Components",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/overview.html"
        }
      ]
    },
    {
      "id": "step5",
      "title": "Validate GPU Visibility in Kubernetes",
      "description": "Confirm GPUs are properly exposed to Kubernetes as allocatable resources.",
      "objectives": [
        "Check node allocatable GPU resources",
        "Verify GPU count per node",
        "Check GPU labels and annotations"
      ],
      "expectedCommands": [
        "kubectl describe node dgx-01 | grep -A 10 Allocatable",
        "kubectl get nodes -o=custom-columns=NAME:.metadata.name,GPUs:.status.capacity.'nvidia\\.com/gpu'",
        "kubectl describe node dgx-01 | grep nvidia.com"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must verify GPU visibility",
          "expectedCommands": ["kubectl describe node", "nvidia.com/gpu"]
        }
      ],
      "hints": [
        "Look for 'nvidia.com/gpu: 8' in Allocatable section",
        "Each DGX node should show 8 GPUs",
        "GFD adds labels like nvidia.com/gpu.product",
        "MIG mode changes GPU count appearance",
        "Check Capacity vs Allocatable for any limits"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "GPU Resources in Kubernetes",
          "url": "https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/"
        }
      ]
    },
    {
      "id": "step6",
      "title": "Run GPU Test Workload",
      "description": "Deploy a test pod requesting GPU resources to validate the complete GPU stack.",
      "objectives": [
        "Create GPU test pod specification",
        "Deploy test pod",
        "Verify GPU access inside container",
        "Run nvidia-smi in container"
      ],
      "expectedCommands": [
        "kubectl run gpu-test --image=nvidia/cuda:12.0-base --restart=Never --limits=nvidia.com/gpu=1 -- nvidia-smi",
        "kubectl logs gpu-test",
        "kubectl delete pod gpu-test"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must run GPU test workload",
          "expectedCommands": ["kubectl run", "kubectl logs"]
        }
      ],
      "hints": [
        "Request GPU with resources.limits.nvidia.com/gpu: 1",
        "nvidia-smi output in logs confirms GPU access",
        "Test pod should complete with exit code 0",
        "Use official NVIDIA CUDA images from NGC",
        "For multi-GPU, increase the limit value"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "Running GPU Pods",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html"
        }
      ]
    },
    {
      "id": "step7",
      "title": "Troubleshoot Common Issues",
      "description": "Learn to diagnose and resolve common GPU Operator issues.",
      "objectives": [
        "Check operator logs for errors",
        "Verify node taints and tolerations",
        "Diagnose pending GPU pods",
        "Check for resource conflicts"
      ],
      "expectedCommands": [
        "kubectl logs -n gpu-operator deployment/gpu-operator",
        "kubectl describe pod -n gpu-operator nvidia-device-plugin-daemonset-xxxxx",
        "kubectl get events -n gpu-operator --sort-by='.lastTimestamp'"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must check for issues",
          "expectedCommands": [
            "kubectl logs",
            "kubectl describe pod",
            "kubectl get events"
          ]
        }
      ],
      "hints": [
        "Common issue: Driver mismatch between host and operator",
        "Check for NVIDIA driver loaded on host: lsmod | grep nvidia",
        "Pending pods often indicate resource contention",
        "Events show scheduling and runtime failures",
        "DaemonSet pods should run on all GPU nodes"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "GPU Operator Troubleshooting",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/troubleshooting.html"
        }
      ]
    }
  ],
  "successCriteria": [
    "Verified Kubernetes cluster prerequisites",
    "Configured NVIDIA Helm repository",
    "Deployed GPU Operator successfully",
    "All operator components running",
    "GPUs visible as allocatable resources",
    "Successfully ran GPU test workload",
    "Understood troubleshooting procedures"
  ],
  "estimatedTime": 40,
  "prerequisites": ["domain3-container-runtime"],
  "tags": [
    "kubernetes",
    "gpu-operator",
    "helm",
    "container",
    "cloud-native",
    "intermediate",
    "domain3"
  ],
  "tier": 2,
  "commandFamilies": ["container-tools"],
  "explanationGateId": "gate-domain3-k8s-gpu-operator"
}
